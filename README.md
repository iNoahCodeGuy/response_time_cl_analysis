# ðŸš— Lead Response Time Analyzer

A Streamlit application that analyzes the impact of response time on lead close rates. Built with rigorous statistical methods and designed to explain complex concepts to non-technical users.

## ðŸŽ¯ What This App Does

This application helps you answer a critical sales question:

> **"Does responding faster to leads increase the chance of closing a deal?"**

Upload your lead data, and the app will:

1. **Analyze response time patterns** - See how leads are distributed across response time buckets
2. **Calculate close rates** - Compare conversion rates for fast vs. slow responses
3. **Run statistical tests** - Determine if differences are statistically significant
4. **Control for confounders** - Account for lead source and sales rep effects
5. **Explain everything** - Step-by-step explanations for non-technical users

## ðŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- pip (Python package manager)

### Installation

```bash
# Clone the repository
git clone https://github.com/iNoahCodeGuy/response_time_cl_analysis.git
cd response_time_cl_analysis

# Create a virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Run the app
streamlit run app.py
```

The app will open in your browser at `http://localhost:8501`

### Try with Sample Data

Don't have data ready? Click **"Load Sample Data"** to generate 10,000 realistic sample leads and explore the app's features.

## ðŸ“Š Data Requirements

Your data should include these columns (names can vary):

| Required Data | Example Column Names |
|--------------|---------------------|
| Lead arrival time | `created_at`, `lead_time`, `timestamp` |
| First response time | `first_response`, `replied_at`, `contacted_at` |
| Lead source | `source`, `channel`, `lead_source` |
| Sales rep | `rep`, `agent`, `salesperson` |
| Order outcome | `ordered`, `sold`, `converted` |

### Supported Formats

- **File types**: CSV, XLSX, XLS
- **Date formats**: ISO, US, European, Excel serial numbers
- **Outcome values**: Boolean, 1/0, Yes/No, text values like "Ordered"

## ðŸ”¬ Analysis Features

The application performs comprehensive statistical analysis:

- **Descriptive statistics** - Close rates by response time bucket with confidence intervals
- **Chi-square test** - Tests for overall relationship between response time and conversion
- **Z-test for proportions** - Pairwise bucket comparisons with statistical significance
- **Logistic regression** - Effect size controlling for lead source and other confounders
- **Weekly trends analysis** - Week-over-week pattern analysis to assess consistency
- **Confounding assessment** - Systematic evaluation of potential bias in results
- **Step-by-step explanations** - Plain-English explanations of statistical concepts for non-technical users

## ðŸ“ˆ Understanding the Results

### Key Metrics

| Metric | What It Means |
|--------|---------------|
| **Close Rate** | Percentage of leads that converted to orders |
| **P-Value** | Probability the result is due to chance (< 0.05 = significant) |
| **Odds Ratio** | How much higher/lower the odds of ordering are vs. reference |
| **Confidence Interval** | Range where the true value likely falls |

### Interpreting Significance

- **Significant (p < 0.05)**: Differences unlikely due to random chance
- **Not Significant (p â‰¥ 0.05)**: Cannot rule out random variation

## ðŸ—ï¸ Project Structure

```
response_time_cl_analysis/
â”œâ”€â”€ app.py                      # Main Streamlit application
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ README.md                   # This file
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ settings.py             # Configuration constants
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ loader.py               # File loading and validation
â”‚   â”œâ”€â”€ datetime_parser.py      # Date/time format detection
â”‚   â”œâ”€â”€ column_mapper.py        # Column mapping logic
â”‚   â”œâ”€â”€ sample_generator.py     # Sample data generation
â”‚   â”œâ”€â”€ weeks_analyzer.py       # Weeks of data analysis
â”‚   â””â”€â”€ export.py               # Data export functionality
â”‚
â”œâ”€â”€ analysis/
â”‚   â”œâ”€â”€ preprocessing.py        # Response time bucketing
â”‚   â”œâ”€â”€ descriptive.py          # Summary statistics
â”‚   â”œâ”€â”€ statistical_tests.py    # Chi-square, z-tests
â”‚   â”œâ”€â”€ regression.py           # Logistic regression
â”‚   â””â”€â”€ weekly_trends.py        # Week-over-week trend analysis
â”‚
â”œâ”€â”€ explanations/
â”‚   â”œâ”€â”€ templates.py            # Plain-English explanation templates
â”‚   â”œâ”€â”€ formulas.py             # LaTeX formulas
â”‚   â”œâ”€â”€ common.py               # Common explanation utilities
â”‚   â”œâ”€â”€ explainers.py           # Statistical concept explainers
â”‚   â”œâ”€â”€ p_value.py              # P-value explanations
â”‚   â”œâ”€â”€ odds_ratio.py           # Odds ratio explanations
â”‚   â”œâ”€â”€ confidence_intervals.py # Confidence interval explanations
â”‚   â””â”€â”€ verification_panels.py  # Verification and validation panels
â”‚
â””â”€â”€ components/
    â”œâ”€â”€ upload.py               # File upload interface
    â”œâ”€â”€ mapping_ui.py           # Column mapping interface
    â”œâ”€â”€ settings_panel.py       # Settings sidebar
    â”œâ”€â”€ step_display.py         # Step-by-step explanations
    â”œâ”€â”€ charts.py               # Plotly visualizations
    â””â”€â”€ results_dashboard.py    # Results display
```

## âš ï¸ Limitations

This analysis has important limitations to keep in mind:

1. **Correlation â‰  Causation** - This is observational data, not a controlled experiment
2. **Unmeasured Confounders** - We can only control for variables we measure
3. **Selection Bias** - Only analyzes leads that received responses
4. **External Validity** - Results may not generalize to different contexts

**For causal conclusions**, note that this observational analysis has limitations in establishing causation. We cannot deliberately delay responses to test the relationship.

## ðŸ› ï¸ Customization

### Response Time Buckets

Edit `config/settings.py` to change default bucket boundaries:

```python
DEFAULT_BUCKETS = [0, 15, 30, 60, float('inf')]
DEFAULT_BUCKET_LABELS = ['0-15 min', '15-30 min', '30-60 min', '60+ min']
```

### Significance Level

Change the default alpha level in `config/settings.py`:

```python
DEFAULT_ALPHA = 0.05  # Change to 0.01 for stricter threshold
```

## ðŸ“š Statistical Methods

### Chi-Square Test of Independence

Tests whether response time bucket and order outcome are independent:

$$\chi^2 = \sum \frac{(O - E)^2}{E}$$

### Z-Test for Proportions

Compares close rates between two specific buckets:

$$z = \frac{\hat{p}_1 - \hat{p}_2}{\sqrt{\hat{p}(1-\hat{p})\left(\frac{1}{n_1} + \frac{1}{n_2}\right)}}$$

### Logistic Regression

Models log-odds of ordering as a function of response time and controls:

$$\log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1 \cdot \text{bucket} + \beta_2 \cdot \text{source}$$

## ðŸ¤ Contributing

Contributions are welcome! Areas for improvement:

- Additional statistical tests
- More visualization options
- Enhanced confounding diagnostics
- Additional data export formats

## ðŸ“ License

This project is for internal use. Modify and distribute as needed for your organization.

## ðŸ™ Acknowledgments

Built with:
- [Streamlit](https://streamlit.io/) - App framework
- [Pandas](https://pandas.pydata.org/) - Data manipulation
- [Plotly](https://plotly.com/) - Interactive visualizations
- [Statsmodels](https://www.statsmodels.org/) - Statistical models
- [SciPy](https://scipy.org/) - Statistical tests

---

*"Does response time matter? Now you have the data to know for sure."*
